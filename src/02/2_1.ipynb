{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleMlp(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        vec_length:int=16,\n",
    "        hidden_unit_1:int=8,\n",
    "        hidden_unit_2:int=2\n",
    "        ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            vec_length: 入力ベクトルの長さ\n",
    "            hidden_unit_1: 1つ目の線形層のニューロン数\n",
    "            hidden_unit_2: 2つ目の線形層のニューロン数\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        # 1つ目の線形層\n",
    "        self.layer1 = nn.Linear(vec_length, hidden_unit_1)\n",
    "        # 活性化関数\n",
    "        self.relu = nn.ReLU()\n",
    "        # 2つ目の線形層\n",
    "        self.layer2 = nn.Linear(hidden_unit_1, hidden_unit_2)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"_準伝播は、線形層->ReLU->線形層\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): (B, D_out)\n",
    "                B: バッチサイズ, D_out: ベクトルの長さ.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: (B, D_out)\n",
    "                B: バッチサイズ, D_out: ベクトルの長さ.\n",
    "        \"\"\"\n",
    "\n",
    "        out = self.layer1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.layer2(out)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.1308,  1.1351,  0.5849, -1.0717,  0.2851, -0.1508, -1.2939, -1.1274,\n",
       "         -0.5641,  0.1215, -2.3718,  0.6491, -0.7139,  0.7554,  0.4176,  0.6958],\n",
       "        [-1.7107, -1.0270,  0.7514, -0.4281,  0.1143, -1.0823, -0.3587,  0.3525,\n",
       "         -2.3782, -1.2258, -0.9349, -1.3652,  0.6703,  0.8533, -1.0023, -0.3132],\n",
       "        [ 1.4142,  0.3184, -0.2266, -0.0883,  0.5979,  1.1003,  0.9656,  0.3189,\n",
       "         -0.7393, -0.5681, -0.0336,  0.7613, -1.3821,  0.4934, -0.4052,  0.2128],\n",
       "        [ 0.3915,  1.7601, -0.3167,  0.2510, -0.0469, -0.8364,  1.2284,  0.9240,\n",
       "         -0.4840, -0.2638,  2.2087, -1.3951,  1.5534, -0.4892,  0.6302, -0.6226]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vec_length = 16\n",
    "hidden_unit_1 = 8\n",
    "hidden_unit_2 = 2\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "x = torch.randn(batch_size, vec_length)\n",
    "\n",
    "net = SimpleMlp(vec_length=vec_length, hidden_unit_1=hidden_unit_1, hidden_unit_2=hidden_unit_2)\n",
    "\n",
    "out = net(x)\n",
    "\n",
    "print(out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21a447d43d212849e540c6c38cb6eb2460dc2380e24f4b0de591296981a71bc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
