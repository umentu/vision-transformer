{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLP Head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MLP HeadはViT分類期。\n",
    "Encoderで出力されたデータをLayer Normalizationして線形層を通すだけ。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数式表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$z_L$ を$L$個のEncoder Blockで処理したデータとする。この中からクラストークン$z_L^{cls} \\in \\mathbb{R}^{D}$のみ抜き取る。\n",
    "\n",
    "\n",
    "これにLayer Normalizationを適用するので$LN(z_L^{cls})$となる。さらに線形層$W^y \\in \\mathbb{R}^{D \\times M}$である。但し$M$は分類するクラス数である。\n",
    "\n",
    "したがってMLP Head出の処理は次のように表現できる。\n",
    "\n",
    "$$z_L \\rightarrow LN(z_L^{cls}) W^y \\in \\mathbb{R}^{M} $$\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class VitMLPHeader(nn.Module):\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_dim:int = 384,\n",
    "        class_num: int = 10\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            emb_dim (int, optional): 埋め込みベクトルの長さ. Defaults to 384.\n",
    "            class_num (int, optional): 分類するクラス数. Defaults to 10.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.mlp_header = nn.Sequential(\n",
    "            nn.LayerNorm(emb_dim),\n",
    "            nn.Linear(emb_dim, class_num)\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): Encoder後のデータ。(B, N, D)\n",
    "                B: バッチ数\n",
    "                N: トークン数\n",
    "                D: 埋め込みベクトルの長さ\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: MLP Headerの出力。(B, N, M)\n",
    "                B: バッチ数\n",
    "                N: トークン数\n",
    "                M: 分類するクラス数 \n",
    "        \"\"\"\n",
    "        # クラストークンのみ抜き取る\n",
    "        ## (B, N, D) -> (B, D)\n",
    "        cls_token = z[:, 0]\n",
    "\n",
    "        # MLP Header\n",
    "        ## (B, D) -> (B, M)\n",
    "        out = self.mlp_header(cls_token)\n",
    "\n",
    "        return out\n",
    "\n",
    "\n",
    "mlp_header = VitMLPHeader()\n",
    "z = mlp_header.forward(z_0)\n",
    "\n",
    "print(z.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# emb: 埋め込み。embedded\n",
    "\n",
    "class VitInputLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 3,\n",
    "        emb_dim: int = 384,\n",
    "        num_patch_row: int = 2,\n",
    "        image_size: int = 32\n",
    "    ):\n",
    "        \"\"\"        \n",
    "        Args:\n",
    "            in_channels (int, optional): 入力画像のチャンネル数. Defaults to 3.\n",
    "            emb_dim (int, optional): 埋め込み後のベクトルの長さ. Defaults to 384.\n",
    "            num_patch_row (int, optional): 高さ方向のパッチ数. Defaults to 2.\n",
    "            image_size (int, optional): 入力画像の1辺の大きさ. Defaults to 32.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_patch_row = num_patch_row\n",
    "        self.image_size = image_size\n",
    "\n",
    "        # パッチ数\n",
    "        self.num_patch = self.num_patch_row ** 2\n",
    "\n",
    "        # パッチの大きさ\n",
    "        self.patch_size = int(self.image_size // self.num_patch_row)\n",
    "\n",
    "        # 乳画像のパッチへの分割 & パッチ埋め込みを一気に行う層\n",
    "        self.patch_emb_layer = nn.Conv2d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.emb_dim,\n",
    "            kernel_size=self.patch_size,\n",
    "            stride=self.patch_size\n",
    "        )\n",
    "\n",
    "        # クラストークン\n",
    "        self.cls_token = nn.parameter.Parameter(\n",
    "                torch.randn(1,1, emb_dim)\n",
    "            \n",
    "        )\n",
    "\n",
    "        # 位置埋め込み\n",
    "        # トークン数(パッチ数+クラストークン数(1))\n",
    "        num_token = self.patch_size + 1\n",
    "        self.pos_emb = nn.parameter.Parameter(\n",
    "            torch.randn(1, self.num_patch+1, emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"前処理\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): （B, C, H, W）\n",
    "                B: バッチサイズ\n",
    "                C: チャンネル数\n",
    "                H: 高さ\n",
    "                W: 幅\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: ViTへの入力。(B, N, D)\n",
    "                B: バッチサイズ\n",
    "                N: トークン数\n",
    "                D: 埋め込みベクトルの長さ\n",
    "        \"\"\"\n",
    "\n",
    "        # パッチの埋め込み\n",
    "\n",
    "        ## P: パッチの1辺のサイズ\n",
    "        ## flattenはパッチ埋め込みの後\n",
    "\n",
    "        ## パッチ埋め込み (B, C, H, W) -> (B, D, H/P, W/P)\n",
    "        z_0 = self.patch_emb_layer(x)\n",
    "\n",
    "        ## flatten (B, D, H/P, W/P) -> (B, D, Np)\n",
    "        ## Np はパッチ数 (= H*W / P**2)\n",
    "        z_0 = z_0.flatten(2)\n",
    "\n",
    "        ## 軸の順番を変更 (B, D, Np) -> (B, Np, D)\n",
    "        z_0 = z_0.transpose(1, 2)\n",
    "\n",
    "        # クラストークンを結合 (B, Np, D) -> (B, N, D)\n",
    "        # cls_token: (1, 1, D) から (B, 1, D)に変換して結合\n",
    "        z_0 = torch.cat(\n",
    "            [self.cls_token.repeat(repeats=(x.size(0), 1, 1)), z_0],\n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "        # 位置埋め込み\n",
    "        z_0 = z_0 + self.pos_emb\n",
    "\n",
    "        return z_0\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        emb_dim: int = 384,\n",
    "        head: int = 3,\n",
    "        dropout: float = 0\n",
    "    ):\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            emb_dim (int, optional): Input Layerから出てくるベクトルの次元. Defaults to 384.\n",
    "            head (int, optional): ヘッドの数. Defaults to 3.\n",
    "            dropout (float, optional): ドロップアウト数. Defaults to 0.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    " \n",
    "        self.emb_dim = emb_dim\n",
    "        self.head = head\n",
    "        self.head_dim = emb_dim // head\n",
    "        self.sqrt_dh = self.head_dim ** 0.5 # softmax関数の時に使う\n",
    "    \n",
    "        # q,k,vの線形層\n",
    "        self.w_q = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.w_k = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "        self.w_v = nn.Linear(emb_dim, emb_dim, bias=False)\n",
    "\n",
    "        # 正規化するときにDropoutをする\n",
    "        self.attn_drop = nn.Dropout(dropout)\n",
    "\n",
    "        # MHSAの結果を出力に埋め込むための線形層\n",
    "        self.w_o = nn.Sequential(\n",
    "            nn.Linear(emb_dim, emb_dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, z: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "\n",
    "        Args:\n",
    "            z (torch.Tensor): MHSAの入力。(B, N, D)\n",
    "                B: バッチ数\n",
    "                N: トークン数\n",
    "                D: ベクトルの次元\n",
    "            \n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: MHSAの出力。(B, N, D)\n",
    "                B: バッチ数\n",
    "                N: トークン数\n",
    "                D: ベクトルの次元\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_num, patch_num, _ = z.size()\n",
    "\n",
    "        # 埋め込み\n",
    "        ## (B, N, D) -> (B, N, D)\n",
    "        q = self.w_q(z)\n",
    "        k = self.w_k(z)\n",
    "        v = self.w_v(z)\n",
    "\n",
    "        # ヘッドを分割\n",
    "        ## h: ヘッド数\n",
    "        ## (B, N, D) -> (B, N, h, D/h)\n",
    "        q = q.view(batch_num, patch_num, self.head, self.head_dim)\n",
    "        k = q.view(batch_num, patch_num, self.head, self.head_dim)\n",
    "        v = q.view(batch_num, patch_num, self.head, self.head_dim)\n",
    "\n",
    "        # transposeして (B, N, h, D/h) から (B, h, N, D/h) に変更する\n",
    "        q = q.transpose(1, 2)\n",
    "        k = k.transpose(1, 2)\n",
    "        v = v.transpose(1, 2)\n",
    "\n",
    "        # qk^T を計算するために kを転地する\n",
    "        k_t = k.transpose(2, 3)\n",
    "\n",
    "        # qk^T\n",
    "        # (B, h, N, D/h) x (B, h, D/h, N) -> (B, h, N, N)\n",
    "        dots = (q @ k_t) / self.sqrt_dh\n",
    "        \n",
    "        # softmax\n",
    "        attn = F.softmax(dots, dim=-1)\n",
    "\n",
    "        # dropout\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        # 加重和 softmax(qt^t/sqrt(Dh))v\n",
    "        ## (B, h, N, N) x (B, h, N, D/h) -> (B, h, N, D/h)\n",
    "        out = attn @ v\n",
    "\n",
    "        # transpose\n",
    "        ## (B, h, N, D/h) -> (B, N, h, D/h)\n",
    "        out = out.transpose(1, 2)\n",
    "\n",
    "        ## (B, N, h, D/h) -> (B, N, D)\n",
    "        out = out.reshape(batch_num, patch_num, self.emb_dim)\n",
    "\n",
    "        # Output\n",
    "        # (B, N, D) -> (B, N, D)\n",
    "        out = self.w_o(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "batch_size = 2\n",
    "channel = 3\n",
    "height = 32\n",
    "weight = 32\n",
    "\n",
    "x = torch.randn(batch_size, channel, height, weight)\n",
    "input_layer = VitInputLayer(num_patch_row=2)\n",
    "z_0 = input_layer(x)\n",
    "\n",
    "mhsa = MultiHeadSelfAttention()\n",
    "z_0 = mhsa(z_0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21a447d43d212849e540c6c38cb6eb2460dc2380e24f4b0de591296981a71bc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
