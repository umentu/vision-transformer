{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# input layerの入力表現"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 流れ\n",
    "\n",
    "1. パッチへ分割\n",
    "   1. 画像をパッチに分割する\n",
    "   2. flattenして、パッチの縦×横×チャンネルの長さのベクトルに変換する\n",
    "2. パッチ埋め込み\n",
    "   1. 1層の線形層で良いベクトルに変換する\n",
    "   2. 良いベクトル:=損失が少ないベクトル\n",
    "3. クラストークンを定義\n",
    "   1. 画像全体の情報を保持する\n",
    "   2. パッチ埋め込みのベクトルの大きさのベクトル\n",
    "   3. 標準正規分布に従った値を設定\n",
    "   4. クラストークンは学習のパラメータ\n",
    "4. 位置埋め込み\n",
    "   1. パッチ埋め込みだけではパッチの位置情報がないため、位置をクラストークンとパッチ埋め込みベクトルに埋め込む\n",
    "   2. 初期値は標準正規分布に従う乱数を設定\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数式表現\n",
    "\n",
    "### 1. 入力画像からflattenまで\n",
    "\n",
    "> $H$: 画像の高さ（pixel）\n",
    ">\n",
    "> $W$: 画像の幅（pixel）\n",
    ">\n",
    "> $C$: 色情報（RGB）\n",
    ">\n",
    "> $N_p$: パッチの個数 \n",
    ">\n",
    "> $P$: パッチの縦横のサイズ（pixel）\n",
    "\n",
    "\n",
    "とすると入力画像を\n",
    "\n",
    "> $\\boldsymbol{x} \\in \\mathbb{R}^{H \\times W \\times C}$\n",
    "\n",
    "\n",
    "flattenした入力画像を\n",
    "\n",
    "> $\\boldsymbol{x_p} \\in \\mathbb{R}^{N_p\\times(P^2 \\cdot C)}$\n",
    "\n",
    "と表せる。\n",
    "\n",
    "flattenした各バッチのベクトルは\n",
    "> $x_p^1, x_p^2, \\dots, x_p^{N_p}$\n",
    "\n",
    "と表す。\n",
    "\n",
    "\n",
    "### 2. パッチ埋め込み\n",
    "\n",
    "> $D$ :「$\\boldsymbol{x_p}$ を埋め込んだベクトルの次元」\n",
    "\n",
    "とすると、$\\boldsymbol{x_p}$を埋め込む線形層の重みは\n",
    "\n",
    "> $E \\in \\mathbb{R}^{(P^2 \\cdot C) \\times D} $ \n",
    "\n",
    "と表せ、各バッチに$E$を適用すると\n",
    "\n",
    "> $x_{p}^i E \\in \\mathbb{R}^D \\quad (i = 1, 2, \\dots, N_p)$ \n",
    "\n",
    "であり、\n",
    "\n",
    "> $x_p E = [ x_p^1 E; x_p^2 E; \\dots, x_p^{N_p} E ] \\in \\mathbb{R}^{N_p \\times D}$\n",
    "\n",
    "である。\n",
    "\n",
    "\n",
    "### 3. クラストークン\n",
    "\n",
    "\n",
    "$x_p E$ にクラストークンを付加する。$x_{class} \\in \\mathbb{R}^D$ を$x_p E$に追加して、\n",
    "\n",
    "> $x_{p+t} E = [ x_{class}; x_p^1E;  x_p^2E; \\dots, x_p^{N_p}E] \\in \\mathbb{R}^{(N_p + 1) \\times D}$\n",
    "\n",
    "である。\n",
    "\n",
    "### 4. 位置埋め込み\n",
    "\n",
    "> トークン数N:「クラストークン+パッチ数」\n",
    "\n",
    "とすると、トークン数は$N = N_p + 1$である。\n",
    "\n",
    "位置埋め込みはD次元ベクトルがトークン数、すなわち\n",
    "\n",
    "> $E_{pos} = [E x_{pos}^{class}; E x_{pos}^1; E x_{pos}^2; \\dots; E x_{pos}^{N_p}] \\in \\mathbb{R}^{(N) \\times D}$\n",
    "\n",
    "であるから、位置埋め込みしたEncoderへの入力$z_0$は\n",
    "\n",
    "> $z_0 = x_{p+t}E + E_{pos} \\in \\mathbb{R}^{(N) \\times D} $\n",
    "\n",
    "である。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Input Layerの実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(B, N, D) = torch.Size([2, 5, 384])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# emb: 埋め込み。embedded\n",
    "\n",
    "class VitInputLayer(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels: int = 3,\n",
    "        emb_dim: int = 384,\n",
    "        num_patch_row: int = 2,\n",
    "        image_size: int = 32\n",
    "    ):\n",
    "        \"\"\"        \n",
    "        Args:\n",
    "            in_channels (int, optional): 入力画像のチャンネル数. Defaults to 3.\n",
    "            emb_dim (int, optional): 埋め込み後のベクトルの長さ. Defaults to 384.\n",
    "            num_patch_row (int, optional): 高さ方向のパッチ数. Defaults to 2.\n",
    "            image_size (int, optional): 入力画像の1辺の大きさ. Defaults to 32.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.emb_dim = emb_dim\n",
    "        self.num_patch_row = num_patch_row\n",
    "        self.image_size = image_size\n",
    "\n",
    "        # パッチ数\n",
    "        self.num_patch = self.num_patch_row ** 2\n",
    "\n",
    "        # パッチの大きさ\n",
    "        self.patch_size = int(self.image_size // self.num_patch_row)\n",
    "\n",
    "        # 乳画像のパッチへの分割 & パッチ埋め込みを一気に行う層\n",
    "        self.patch_emb_layer = nn.Conv2d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.emb_dim,\n",
    "            kernel_size=self.patch_size,\n",
    "            stride=self.patch_size\n",
    "        )\n",
    "\n",
    "        # クラストークン\n",
    "        self.cls_token = nn.parameter.Parameter(\n",
    "                torch.randn(1,1, emb_dim)\n",
    "            \n",
    "        )\n",
    "\n",
    "        # 位置埋め込み\n",
    "        # トークン数(パッチ数+クラストークン数(1))\n",
    "        num_token = self.patch_size + 1\n",
    "        self.pos_emb = nn.parameter.Parameter(\n",
    "            torch.randn(1, self.num_patch+1, emb_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"前処理\n",
    "\n",
    "        Args:\n",
    "            x (torch.Tensor): （B, C, H, W）\n",
    "                B: バッチサイズ\n",
    "                C: チャンネル数\n",
    "                H: 高さ\n",
    "                W: 幅\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: ViTへの入力。(B, N, D)\n",
    "                B: バッチサイズ\n",
    "                N: トークン数\n",
    "                D: 埋め込みベクトルの長さ\n",
    "        \"\"\"\n",
    "\n",
    "        # パッチの埋め込み\n",
    "\n",
    "        ## P: パッチの1辺のサイズ\n",
    "        ## flattenはパッチ埋め込みの後\n",
    "\n",
    "        ## パッチ埋め込み (B, C, H, W) -> (B, D, H/P, W/P)\n",
    "        z_0 = self.patch_emb_layer(x)\n",
    "\n",
    "        ## flatten (B, D, H/P, W/P) -> (B, D, Np)\n",
    "        ## Np はパッチ数 (= H*W / P**2)\n",
    "        z_0 = z_0.flatten(2)\n",
    "\n",
    "        ## 軸の順番を変更 (B, D, Np) -> (B, Np, D)\n",
    "        z_0 = z_0.transpose(1, 2)\n",
    "\n",
    "        # クラストークンを結合 (B, Np, D) -> (B, N, D)\n",
    "        # cls_token: (1, 1, D) から (B, 1, D)に変換して結合\n",
    "        z_0 = torch.cat(\n",
    "            [self.cls_token.repeat(repeats=(x.size(0), 1, 1)), z_0],\n",
    "            dim=1\n",
    "        )\n",
    "\n",
    "        # 位置埋め込み\n",
    "        z_0 = z_0 + self.pos_emb\n",
    "\n",
    "        return z_0\n",
    "\n",
    "batch_size = 2\n",
    "channel = 3\n",
    "height = 32\n",
    "weight = 32\n",
    "\n",
    "x = torch.randn(batch_size, channel, height, weight)\n",
    "input_layer = VitInputLayer(num_patch_row=2)\n",
    "z_0 = input_layer(x)\n",
    "\n",
    "print(f\"(B, N, D) = {z_0.shape}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "21a447d43d212849e540c6c38cb6eb2460dc2380e24f4b0de591296981a71bc3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
